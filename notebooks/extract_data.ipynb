{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Libs and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get libs\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "#import psycopg2 as psy2\n",
    "#from sqlalchemy import create_engine\n",
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    global options, coerce_column_to_numeric, dir_path_saved\n",
    "    options = pd.options.mode.chained_assignment = None\n",
    "    def coerce_column_to_numeric(df,column):\n",
    "        df[column] = df[column].apply(pd.to_numeric, errors='coerce')\n",
    "    dir_path_saved = r'../database_dashboard/'\n",
    "config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 ETL\n",
    "- Create datasets with organized data about the real-state funds.\n",
    "- Clean all the data from the url https://www.fundsexplorer.com.br/ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_funds():\n",
    "    def soup():\n",
    "        print('######################### SOUP ############################')\n",
    "        global table, site\n",
    "        # get the url\n",
    "        url = 'https://www.fundsexplorer.com.br/ranking'\n",
    "        response = requests.get(url)\n",
    "        # open the html parser\n",
    "        site = BeautifulSoup(response.text, 'html.parser')\n",
    "    soup()\n",
    "        \n",
    "\n",
    "    def transform():\n",
    "        global data\n",
    "        data = []\n",
    "        table = site.find(id=\"table-ranking\") \n",
    "        table_head = table.find('thead')\n",
    "        rows = table_head.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('th')\n",
    "            colsd = [ele.get_text(separator=\" \").strip() for ele in cols]\n",
    "            data.append([ele for ele in colsd])\n",
    "    # find the table with the funds list\n",
    "        table_body = table.find('tbody')\n",
    "        rows = table_body.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "    # drop the str \n",
    "            colsd = [ele.text.replace('R$','').replace('%','').replace('.','').replace('N/A','').replace(',','.').strip() for ele in cols]\n",
    "            data.append([ele for ele in colsd])\n",
    "    transform()\n",
    "\n",
    "    def data_append():\n",
    "        global df,hj\n",
    "        # put the data inside a data frame\n",
    "        for x in data : df = pd.DataFrame(data=data)\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.drop(index=0)\n",
    "        hj = dt.date.today()\n",
    "        df['data_extracao'] = hj\n",
    "        '''df.rename(columns={'Código do fundo':'codigo_do_fundo', 'Setor':'setor', 'Preço Atual':'preco_atual', 'Liquidez Diária':'liquidez_diaria',\n",
    "        'Dividendo':'dividendo', 'Dividend Yield':'dividend_yield', 'DY (3M) Acumulado':'dy_3m_acumulado', 'DY (6M) Acumulado':'dy_6m_acumulado',\n",
    "        'DY (12M) Acumulado':'DY_(12M)_Acumulado', 'DY (3M) Média':'dy_3m_media', 'DY (6M) Média':'dy_6m_media',\n",
    "        'DY (12M) Média':'dy_12M_media', 'DY Ano':'dy_ano', 'Variação Preço':'variacao_preco', 'Rentab. Período':'rentabilidade_periodo',\n",
    "        'Rentab. Acumulada':'rentabilidade_acumulada', 'Patrimônio Líq.':'patrimonio_liq', 'VPA':'vpa', 'P/VPA':'p_vpa',\n",
    "        'DY Patrimonial':'dy_patrimonial', 'Variação Patrimonial':'variacao_patrimonial', 'Rentab. Patr. no Período':'rentabilidade_patrimonial_periodo',\n",
    "        'Rentab. Patr. Acumulada':'rentabilidade_patrimonial_acumulada', 'Vacância Física':'vacancia_fisica', 'Vacância Financeira':'vacancia_financeira',\n",
    "        'Quantidade Ativos':'quantidade_ativos', 'Hoje':'hoje'}, inplace=True)'''\n",
    "        #df.to_parquet(r'../database/funds_database.parquet')\n",
    "        df.columns = df.columns.str.lower()\n",
    "        columns = df.columns\n",
    "        columns = columns.str.replace(' ','_',regex=True)\n",
    "        columns = columns.str.replace('á','a')\n",
    "        columns = columns.str.replace('í','i')\n",
    "        columns = columns.str.replace('ô','o')\n",
    "        columns = columns.str.replace('ó','o')\n",
    "        columns = columns.str.replace('â','a')\n",
    "        columns = columns.str.replace('ç','c')\n",
    "        columns = columns.str.replace('é','e')\n",
    "        columns = columns.str.replace('.','',regex=True)\n",
    "        columns = columns.str.replace('(','',regex=True)\n",
    "        columns = columns.str.replace(')','',regex=True)\n",
    "        df.columns = columns\n",
    "    data_append()\n",
    "\n",
    "    def save_dataset():\n",
    "        print('\\n All ETL realeased.')\n",
    "        df.to_parquet(fr'{dir_path_saved}data_mart_all_real_state.parquet',index=False)\n",
    "        print('\\n Data Mart Created')\n",
    "    save_dataset()\n",
    "\n",
    "etl_funds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GUILHE~1.DIA\\AppData\\Local\\Temp/ipykernel_4440/1434718374.py:22: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  collect_data_from_real_state()\n"
     ]
    }
   ],
   "source": [
    "def collect_data_from_real_state():\n",
    "    global csv,csv_1\n",
    "    csv = pd.read_csv(r'../databases/fii_real_state_date.csv','utf-8',engine='python')\n",
    "    csv = csv[';;;;;;;;;'].str.split(';',expand=True)\n",
    "    csv = csv.loc[31:331]\n",
    "    csv.rename(columns={0:'codigo_do_fundo',1:'nome_do_fundo',2:'fechamento_em_moeda', 3:'valor_por_cota',4:'yield_mensal',5:'yield_anual',6:'tipo',7:'período_de_referencia',8:'data_base',9:'data_de_pagamento'},inplace=True)\n",
    "    csv = csv.drop(index=[31,32])\n",
    "    csv['fechamento_em_moeda'] = csv['fechamento_em_moeda'].str.replace('N/A','0')\n",
    "    csv['valor_por_cota'] = csv['valor_por_cota'].str.replace(',','.')\n",
    "    csv['fechamento_em_moeda'] = csv['fechamento_em_moeda'].str.replace(',','.')\n",
    "    csv['valor_por_cota'] = csv['valor_por_cota'].astype('float64')\n",
    "    csv['fechamento_em_moeda'] = csv['fechamento_em_moeda'].astype('float64')\n",
    "    csv['yield_mensal'] = csv['yield_mensal'].str.replace('N/A','0')\n",
    "    csv['yield_anual'] = csv['yield_anual'].str.replace('N/A','0')\n",
    "    csv['yield_mensal'] = csv['yield_mensal'].str.replace(',','.')\n",
    "    csv['yield_anual'] = csv['yield_anual'].str.replace(',','.')\n",
    "    csv['data_de_pagamento'] = csv['data_de_pagamento'].str.replace('/','-')\n",
    "    csv['data_de_pagamento'] = csv['data_de_pagamento'].astype('datetime64')\n",
    "    csv['data_base'] = csv['data_base'].str.replace('/','-')\n",
    "    csv['data_base'] = csv['data_base'].astype('datetime64')\n",
    "    csv.to_parquet(r'../database_dashboard/data_mart_real_state_date.parquet',index=False)\n",
    "collect_data_from_real_state()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b78c8e87069e5fba1a84a38671d72022b5e42ef4fce698dc1e5be0be1a061dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('test_work': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
